<#import "/templates/guide.adoc" as tmpl>
<#import "/templates/links.adoc" as links>

<@tmpl.guide
title="Health checks for multi-site deployments"
summary="Validating the health of a multi-site deployment" >

When customers run the {project_name} https://www.keycloak.org/high-availability/introduction[multi-site setup] in their Kubernetes environment,
they should be able to point their monitoring to specific URLs to see if everything is up and running as expected.

This page attempts to provide an overview of such URLs,
Kubernetes resources and Healthcheck endpoints derived from a multi-site setup of {project_name}.

== Overview

A Proactive monitoring strategy, aiming to detect and alert on issues before they impact users is key for a highly resilient and highly available {project_name} application.

Health checks across various architectural components (like application health, load balancing, caching, and overall system status) are critical for:

* *Ensuring High Availability*: By verifying that all sites and the load balancer are operational, it helps guarantee that the system can handle requests even if one site goes down.
* *Maintaining Performance*: Checking the health and distribution of the {jdgserver_name} cache ensures that {project_name} can maintain optimal performance by efficiently handling sessions and other temporary data.
* *Operational Resilience*: By continuously monitoring the health of both {project_name} and its dependencies within the Kubernetes environment, the system can quickly identify and possibly auto-remediate issues, reducing downtime.

== How to set it up

Prerequisite:

. https://kubernetes.io/docs/tasks/tools/#kubectl[Kubectl CLI is installed and configured].

. Install https://jqlang.github.io/jq/download/[jq] if it is not available on your OS already.

== More on the specific Health Checks

=== {project_name} Load Balancer and Sites

Verifies the health of the {project_name} application through its load balancer and both primary and backup sites. This ensures that {project_name} is accessible and that the load balancing mechanism is functioning correctly across different geographical or network locations.

This command returns the health status of the {project_name} application's connection to its configured database, thus confirming the reliability of db connections.
This is only available on the management port, and not available from the external URL.
In a Kubernetes setup, the sub-status `health/ready` is checked periodically to make the Pod as ready.

[source,bash]
----
curl -s https://keycloak:managementport/health
----

This command verifies the `lb-check` endpoint of the load balancer and ensures the {project_name} application cluster is up and running.
[source,bash]
----
curl -s https://keycloak-load-balancer-url/lb-check
----

These commands will return the running status of the Site A and Site B of the {project_name} in a cross-site setup (be it Active/Passive or Active/Active).

[source,bash]
----
curl -s https://keycloak_site_a_url/lb-check
curl -s https://keycloak_site_b_url/lb-check
----

=== {jdgserver_name} Cache Health
Check the health of the default cache manager and individual caches in an external {jdgserver_name} cluster.
This is vital for {project_name} performance and reliability,
as {jdgserver_name} is often used for distributed caching and session clustering in {project_name} deployments.

This command returns the overall health of the {jdgserver_name} cache manager, this is useful as the Admin user doesn't need to provide user credentials to get the health status.
[source,bash]
----
curl -s https://infinispan_rest_url/rest/v2/cache-managers/default/health/status
----

Whereas for these health checks, Admin user needs to provide the {jdgserver_name} user credentials as part of the request to peek into the overall health of the external {jdgserver_name} cluster caches.
[source,bash]
----
curl -u <infinispan_user>:<infinispan_pwd> -s https://infinispan_rest_url/rest/v2/cache-managers/default/health \
 | jq 'if .cluster_health.health_status == "HEALTHY" and (all(.cache_health[].status; . == "HEALTHY")) then "HEALTHY" else "UNHEALTHY" end'
----

Optionally you can run the above command without the `jq` filter `'if .cluster_health.health_status == "HEALTHY" and (all(.cache_health[].status; . == "HEALTHY")) then "HEALTHY" else "UNHEALTHY" end'` to see the full details, this filter is a convenience to compute the overall health based on the individual cache health.

=== {jdgserver_name} Cluster Distribution
Assesses the distribution health of the {jdgserver_name} cluster, ensuring that the cluster's nodes are correctly distributing data. This step is essential for the scalability and fault tolerance of the caching layer.

You can modify the `expectedCount 3` argument to match the total nodes in the cluster and validate if they are healthy or not.
[source,bash]
----
curl <infinispan_user>:<infinispan_pwd> -s https://infinispan_rest_url/rest/v2/cluster\?action\=distribution \
 | jq --argjson expectedCount 3 'if map(select(.node_addresses | length > 0)) | length == $expectedCount then "HEALTHY" else "UNHEALTHY" end'
----

=== Overall, {jdgserver_name} System Health
Uses `kubectl` CLI tool to query the health status of {jdgserver_name} clusters and the {project_name} service in the specified namespace. This comprehensive check ensures that all components of the {project_name} deployment are operational and correctly configured within the Kubernetes environment.

[source,bash]
----
kubectl get infinispan -n <NAMESPACE> -o json  \
| jq '.items[].status.conditions' \
| jq 'map({(.type): .status})' \
| jq 'reduce .[] as $item ([]; . + [keys[] | select($item[.] != "True")]) | if length == 0 then "HEALTHY" else "UNHEALTHY: " + (join(", ")) end'
----

=== {project_name} Readiness in Kubernetes
Specifically, checks for the readiness and rolling update conditions of {project_name} deployments in Kubernetes,
ensuring that the {project_name} instances are fully operational and not undergoing updates that could impact availability.

[source,bash]
----
kubectl wait --for=condition=Ready --timeout=10s keycloaks.k8s.keycloak.org/keycloak -n <NAMESPACE>
kubectl wait --for=condition=RollingUpdate=False --timeout=10s keycloaks.k8s.keycloak.org/keycloak -n <NAMESPACE>
----

</@tmpl.guide>
